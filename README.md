# AutoPPA - automatic RTL code optimization

## Introduction

This repository introduces AutoPPA - an AI agent which optimizes RTL code for Power, Performance, Area (PPA). In addition to the agent, a benchmark containing 5 optimization tasks is included. Finally, several baselines are provided to see how the AI's performance compares across the benchmark tasks.

## Pre-requisites

[Download Icarus Verilog](https://steveicarus.github.io/iverilog/usage/installation.html) for simulation.

```
sudo apt install iverilog
```

[Download Yosys](https://github.com/YosysHQ/yosys/blob/main/README.md#installation) for synthesis.

```
sudo apt install yosys
```

Clone this repository and install it as a `pip` package

```
git clone https://github.com/j-silv/autoppa.git
cd autoppa
pip install -e .
```

## Benchmark

The benchmark uses RTL code gathered from the [PicoRV32 project](https://github.com/YosysHQ/picorv32). This repo is used because the core is configurable with respect to PPA, and thus useful benchmarks can be created from non-optimized (one particular configuration) vs. optimized RTL (a different configuration).

The task breakdown and corresponding optimized baseline are as follows:

### Task 1. Increase performance of the `picorv32_pcpi_mul` module
- **Reference**: `picorv32_pcpi_mul` module in the `picorv32.v` top-level module
- **Optimized**: `picorv32_pcpi_fast_mul` module which is enabled with the `ENABLE_FAST_MUL` configuration flag

### Task 2. Reduce the area of the `picorv32_pcpi_mul` module
- **Reference**: re-used `picorv32_pcpi_fast_mul` module (Task #1) which has an improved performance, but higher area usage
- **Optimized**: re-used `picorv32_pcpi_mul` module (Task #1)

### Task 3. Increase performance of the `picorv32_pcpi_div` module
- **Reference**: `picorv32_pcpi_div` module in the `picorv32.v` top-level module
- **Optimized**: Faster divide module generated by iteratively prompting ChatGPT

### Task 4. Reduce the area of the `picorv32_pcpi_div` module
- **Reference**: re-used optimized `picorv32_pcpi_div` module (Task #3) which has improved performance, but higher area usage
- **Optimized**: re-used `picorv32_pcpi_div` module (Task #3)

### Task 5. Reduce the power of the `picorv32_pcpi_div` module
- **Reference**: re-used `picorv32_pcpi_div` module (Task #3)
- **Optimized**: Power-efficient divide module generated by iteratively prompting ChatGPT

Here is an example of how to run one of the benchmarks.

First we simulate Verilog code for Task #1 optimization (performance improvement).

```
autoppa sim 1 baseline/reference/task1.v
```

Then we synthesize the design to get area metrics:

```
autoppa synth 1 baseline/reference/task1.v
```

## Baseline

There are mainly 3 baselines considered for the benchmark:

1. Reference design (trivial)
2. Optimized design (mix between Pico configuration flags/ChatGPT iteratively prompted)
3. Yosys optimization command-line flags

## Technology

- OpenAI `gpt-5-mini` model as the LLM brain
- Icarus Verilog for simulation
- Yosys for RTL synthesis
- Python for everything else